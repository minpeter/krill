# Test config with smaller dataset for testing
vocab_size: 48000
hub_tokenizer_id: pretraining/fw2-edu-kr-tokenizer-48k

# krill preprocess
sequence_len: 1024
dataset_prepared_path: ./artifacts/webtext-test
dataset_prepared_min_length: 150

preprocess_memory_efficient: false
preprocess_chunk_size: 100

datasets:
  - path: minpeter/fineweb-2-edu-korean
    split: train[:100]  # Very small for testing
    text_column: text

# krill train
hub_model_id: minpeter/webtext-test
output_dir: ./artifacts/models/webtext-test

num_epochs: 1
learning_rate: 1e-3
weight_decay: 0.01
optimizer: muon
muon_implementation: moonlight

micro_batch_size: 1
gradient_accumulation_steps: 1

model_config_name: pico