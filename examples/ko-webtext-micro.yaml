# krill train-tokenizer
vocab_size: 32000
hub_tokenizer_id: pretraining/fw2-edu-kr-tokenizer-48k

# krill preprocess
sequence_len: 8192
dataset_prepared_path: ./artifacts/webtext-8k
dataset_prepared_min_length: 150

datasets:
  - path: HAERAE-HUB/KOREAN-WEBTEXT
    split: train[:10_000]
    text_column: text

# krill train
hub_model_id: minpeter/webtext-8k-micro-250801
output_dir: ./artifacts/models/webtext-8k-micro-250801

num_epochs: 1
learning_rate: 1e-3
weight_decay: 0.01
optimizer: muon
muon_implementation: moonlight

micro_batch_size: 1
gradient_accumulation_steps: 1

model_config_name: micro
